{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Project Personal.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrvghEn4L0Ch",
        "outputId": "b86a7e5b-6b33-4517-84ae-c9403c231ee8"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/gdrive\")\r\n",
        "# !pip install sweetviz\r\n",
        "# import sweetviz as sv\r\n",
        "import datetime\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from math import sin,cos,pi\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn import svm\r\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\r\n",
        "from matplotlib.colors import LinearSegmentedColormap\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from xgboost.sklearn import XGBClassifier\r\n",
        "# %matplotlib inline\r\n",
        "plt.style.use('seaborn')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Requirement already satisfied: sweetviz in /usr/local/lib/python3.6/dist-packages (2.0.4)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from sweetviz) (2.11.2)\n",
            "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in /usr/local/lib/python3.6/dist-packages (from sweetviz) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from sweetviz) (1.19.4)\n",
            "Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.6/dist-packages (from sweetviz) (4.54.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.6/dist-packages (from sweetviz) (1.4.1)\n",
            "Requirement already satisfied: importlib-resources>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sweetviz) (3.3.0)\n",
            "Requirement already satisfied: matplotlib>=3.1.3 in /usr/local/lib/python3.6/dist-packages (from sweetviz) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.11.1->sweetviz) (1.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2.8.1)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources>=1.2.0->sweetviz) (3.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.3->sweetviz) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.3->sweetviz) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.3->sweetviz) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKtpyR0Jg5ds"
      },
      "source": [
        "def Time_Formatx(x):\r\n",
        "    # Formatting Time\r\n",
        "\r\n",
        "    if x == 2400:\r\n",
        "        x = 0\r\n",
        "\r\n",
        "    x = \"{0:04d}\".format(int(x))\r\n",
        "    T = datetime.time(int(x[0:2]), int(x[2:4]))\r\n",
        "    \r\n",
        "    return T\r\n",
        "\r\n",
        "\r\n",
        "def stats(g):\r\n",
        "    # Statistical Information for a Group\r\n",
        "\r\n",
        "    return {'mean':g.mean(), 'variance':g.var(), 'count':g.count(), 'min':g.min(), 'max':g.max()}\r\n",
        "\r\n",
        "\r\n",
        "def dataOverview(Airlines, Airports, Flights):\r\n",
        "\r\n",
        "    # Dataset descriptions\r\n",
        "\r\n",
        "    print(Flights.info(verbose = True, null_counts=True))\r\n",
        "    print(Airlines.info(verbose = True, null_counts=True))\r\n",
        "    print(Airports.info(verbose = True, null_counts=True))\r\n",
        "\r\n",
        "\r\n",
        "    # Cancellation Reasons\r\n",
        "\r\n",
        "    cancelled = Flights['CANCELLATION_REASON']\r\n",
        "    cancelled.dropna(inplace=True)\r\n",
        "    cancelledCount = dict(cancelled.value_counts())\r\n",
        "    labels = ['Weather','Airline','National Air System','Security']\r\n",
        "    sizes = cancelledCount.values()\r\n",
        "\r\n",
        "    fig, ax = plt.subplots(figsize=(8,8))\r\n",
        "    ax.pie(sizes, labels=labels, pctdistance=1.25, labeldistance=1.45, autopct='%1.2f%%', startangle=90, textprops={'fontsize': 20})\r\n",
        "    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # Flights on Different Days of Week\r\n",
        "\r\n",
        "    daysOfWeek = Flights['DAY_OF_WEEK']\r\n",
        "    dayCounts = dict(daysOfWeek.value_counts())\r\n",
        "    dayFreq = {}\r\n",
        "    for day in sorted(dayCounts):\r\n",
        "        dayFreq[day] = dayCounts[day]\r\n",
        "\r\n",
        "    plt.figure(figsize=(12,8))\r\n",
        "    flightFreq = list(dayFreq.values())\r\n",
        "    flightFreq.append(dayFreq[1]) # add monday\r\n",
        "    flightFreq.append(dayFreq[2]) # add tuesday\r\n",
        "    days = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun','Mon.','Tue...']\r\n",
        "    plt.plot(days,flightFreq)\r\n",
        "    plt.xlabel(\"Days of week\", fontsize=16)\r\n",
        "    plt.ylabel(\"No of flights\", fontsize=16)\r\n",
        "    plt.title(\"No of flights on days of week\", fontsize=16)\r\n",
        "    plt.tick_params(labelsize=16)\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # Flights in Different Months\r\n",
        "\r\n",
        "    months = Flights['MONTH']\r\n",
        "    monthCounts = dict(months.value_counts())\r\n",
        "    monthFreq = {}\r\n",
        "    for month in sorted(monthCounts):\r\n",
        "        monthFreq[month] = monthCounts[month]\r\n",
        "\r\n",
        "    plt.figure(figsize=(12,8))\r\n",
        "    flightFreq = list(monthFreq.values())\r\n",
        "    monthsArr = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\r\n",
        "    plt.plot(monthsArr, flightFreq)\r\n",
        "    plt.xlabel(\"Months\", fontsize=16)\r\n",
        "    plt.ylabel(\"No of flights\", fontsize=16)\r\n",
        "    plt.title(\"No of flights on different months\", fontsize=16)\r\n",
        "    plt.tick_params(labelsize=16)\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # Delay Threshold\r\n",
        "\r\n",
        "    ttl = Flights.shape[0]\r\n",
        "    threshold = 3\r\n",
        "    delayLessThanThreshold = Flights[Flights['ARRIVAL_DELAY'] <= threshold].shape[0] / ttl\r\n",
        "    print(delayLessThanThreshold)\r\n",
        "\r\n",
        "\r\n",
        "def exploratoryDataAnalysis(df):\r\n",
        "    \r\n",
        "    # # Overall analysis\r\n",
        "\r\n",
        "    # report = sv.analyze(df)\r\n",
        "    # report.show_html(\"EDA.html\")\r\n",
        "\r\n",
        "\r\n",
        "    # Air Traffic Share of Airlines\r\n",
        "\r\n",
        "    plt.subplots(figsize=(15,20))\r\n",
        "    plt.pie(df['AIRLINE'].value_counts(),labels=df['AIRLINE_NAME'].unique(),autopct='%1.0f%%',textprops={'fontsize': 20})\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # Calculating Data Statistics\r\n",
        "\r\n",
        "    Origin_Stats = df['ARRIVAL_DELAY'].groupby(df['ORIGIN']).apply(stats).unstack().sort_values('count',ascending=False)\r\n",
        "    Destination_Stats = df['ARRIVAL_DELAY'].groupby(df['DESTINATION']).apply(stats).unstack().sort_values('count',ascending=False)\r\n",
        "    Airline_Stats = df['ARRIVAL_DELAY'].groupby(df['AIRLINE']).apply(stats).unstack().sort_values('mean')\r\n",
        "    print(Airline_Stats)\r\n",
        "\r\n",
        "\r\n",
        "    # Airline Delays on Different Days of Week\r\n",
        "\r\n",
        "    Days = [\"Monday\", \"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\r\n",
        "    Airline_Day_Stats = pd.DataFrame()\r\n",
        "    for a in df['AIRLINE'].unique():\r\n",
        "        x = df[df['AIRLINE']==a]\r\n",
        "        t = x['ARRIVAL_DELAY'].groupby(df['DAY']).mean()\r\n",
        "        Airline_Day_Stats[a]=t\r\n",
        "    Airline_Day_Stats.dropna(inplace=True)\r\n",
        "    print(Airline_Day_Stats)\r\n",
        "\r\n",
        "    sns.set(context=\"paper\")\r\n",
        "    plt.subplots(figsize=(10,8))\r\n",
        "    plt.title(\"Mean Delay for Airline Vs. Day of Week\")\r\n",
        "    sns.heatmap(Airline_Day_Stats, linewidths=0.01, cmap=LinearSegmentedColormap.from_list('rg',[\"g\", \"w\", \"r\"], N=256),robust=True,yticklabels=Days)\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # Busiest airports and Airlines\r\n",
        "\r\n",
        "    Airports = df['DESTINATION_CITY'].groupby(df[\"DESTINATION_CITY\"]).count().sort_values(ascending=False).iloc[:11].keys().tolist()\r\n",
        "    map = df[['AIRLINE_NAME','DESTINATION_CITY','ARRIVAL_DELAY']]\r\n",
        "\r\n",
        "    frames = list()\r\n",
        "    for x in Airports:\r\n",
        "        frames.append(map.loc[map[\"DESTINATION_CITY\"] == x])\r\n",
        "    map = pd.concat(frames)\r\n",
        "\r\n",
        "    airline_city_delay = pd.DataFrame()\r\n",
        "    for airlines in map[\"AIRLINE_NAME\"].unique():\r\n",
        "        t = map.loc[map[\"AIRLINE_NAME\"] == airlines]\r\n",
        "        temp = t[\"ARRIVAL_DELAY\"].groupby(t[\"DESTINATION_CITY\"]).mean()\r\n",
        "        airline_city_delay[airlines] = temp\r\n",
        "\r\n",
        "    sns.set(context=\"paper\")\r\n",
        "    plt.subplots(figsize=(10,8))\r\n",
        "    plt.title(\"Mean Delay for Airline Vs. Destination Airports\")\r\n",
        "    sns.heatmap(airline_city_delay, linewidths=0.01, cmap=LinearSegmentedColormap.from_list('rg',[\"g\", \"w\", \"r\"], N=256),robust=True,yticklabels=Airports)\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # Distance and Delay\r\n",
        "\r\n",
        "    map = df[[\"DISTANCE\",\"ARRIVAL_DELAY\",\"AIRLINE_NAME\"]].copy()\r\n",
        "    interval = list()\r\n",
        "    for i in range(0,5000,100):\r\n",
        "        interval.append(i)\r\n",
        "\r\n",
        "    map[\"DISTANCE_INTERVAL\"] = pd.cut(x = map[\"DISTANCE\"], bins = interval)\r\n",
        "    map[\"DISTANCE_MID\"] = map[\"DISTANCE_INTERVAL\"].apply(lambda x : x.mid)\r\n",
        "    newMap = map[\"ARRIVAL_DELAY\"].groupby(map[\"DISTANCE_MID\"]).mean().to_frame()\r\n",
        "    newMap.dropna(inplace=True)\r\n",
        "    newMap.plot.line(title = \"Distance vs Delay graph (Bucket Size:100)\")\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # Distribution of Arrival Delay\r\n",
        "\r\n",
        "    sns.displot(df['ARRIVAL_DELAY'], bins = [i for i in range(-50,100)])\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "\r\n",
        "def preprocess(analysis = False):\r\n",
        "\r\n",
        "    Airlines = pd.read_csv('/content/gdrive/My Drive/ML_Project/airlines.csv')\r\n",
        "    Airports = pd.read_csv('/content/gdrive/My Drive/ML_Project/airports.csv')\r\n",
        "    Flights = pd.read_csv('/content/gdrive/My Drive/ML_Project/flights.csv')\r\n",
        "\r\n",
        "    if analysis:\r\n",
        "        dataOverview(Airlines, Airports, Flights)\r\n",
        "\r\n",
        "\r\n",
        "    # Dropping rows with NaN values and selecting data for January\r\n",
        "\r\n",
        "    Flights = Flights.iloc[:,:23]\r\n",
        "    Flights.dropna(inplace=True)\r\n",
        "    Flights = Flights[Flights[\"MONTH\"]==1]\r\n",
        "    Flights.reset_index(inplace=True)\r\n",
        "\r\n",
        "\r\n",
        "    # Collecting Names of Airlines and Airports\r\n",
        "\r\n",
        "    Airline_Names = {}\r\n",
        "    for i in range(len(Airlines)):\r\n",
        "        Airline_Names[Airlines[\"IATA_CODE\"][i]] = Airlines[\"AIRLINE\"][i]\r\n",
        "\r\n",
        "    Airport_Names = {}\r\n",
        "    for i in range(len(Airports)):\r\n",
        "        Airport_Names[Airports[\"IATA_CODE\"][i]] = Airports[\"AIRPORT\"][i]\r\n",
        "\r\n",
        "    City_Names = {}\r\n",
        "    for i in range(len(Airports)):\r\n",
        "        City_Names[Airports[\"IATA_CODE\"][i]] = Airports[\"CITY\"][i]\r\n",
        "\r\n",
        "\r\n",
        "    # Merging Datasets & Selecting relevant columns\r\n",
        "\r\n",
        "    df = pd.DataFrame()\r\n",
        "    df['DATE'] = pd.to_datetime(Flights[['YEAR','MONTH', 'DAY']])\r\n",
        "    df['DAY'] = Flights[\"DAY_OF_WEEK\"]\r\n",
        "    df['AIRLINE'] = Flights[\"AIRLINE\"]\r\n",
        "    df['AIRLINE_NAME'] = [Airline_Names[Flights[\"AIRLINE\"][x]] for x in range(len(Flights))]\r\n",
        "    df['FLIGHT_NUMBER'] = Flights['FLIGHT_NUMBER']\r\n",
        "    df['TAIL_NUMBER'] = Flights['TAIL_NUMBER']\r\n",
        "    df['ORIGIN'] = Flights['ORIGIN_AIRPORT']\r\n",
        "    df['ORIGIN_AIRPORT_NAME'] = [Airport_Names[Flights[\"ORIGIN_AIRPORT\"][x]] for x in range(len(Flights))]\r\n",
        "    df['ORIGIN_CITY'] = [City_Names[Flights[\"ORIGIN_AIRPORT\"][x]] for x in range(len(Flights))]\r\n",
        "    df['DESTINATION'] = Flights['DESTINATION_AIRPORT']\r\n",
        "    df['DESTINATION_AIRPORT_NAME'] = [Airport_Names[Flights[\"DESTINATION_AIRPORT\"][x]] for x in range(len(Flights))]\r\n",
        "    df['DESTINATION_CITY'] = [City_Names[Flights[\"DESTINATION_AIRPORT\"][x]] for x in range(len(Flights))]\r\n",
        "    df['DISTANCE'] = Flights['DISTANCE']\r\n",
        "    df['SCHEDULED_DEPARTURE'] = Flights['SCHEDULED_DEPARTURE'].apply(Time_Formatx)\r\n",
        "    df['SCHEDULED_ARRIVAL'] = Flights['SCHEDULED_ARRIVAL'].apply(Time_Formatx)\r\n",
        "    df['TAXI_OUT'] = Flights['TAXI_OUT']\r\n",
        "    df['DEPARTURE_DELAY'] = Flights['DEPARTURE_DELAY']\r\n",
        "    df['ARRIVAL_DELAY'] = Flights['ARRIVAL_DELAY']\r\n",
        "    df = df[df.ARRIVAL_DELAY < 500]\r\n",
        "\r\n",
        "    if analysis:\r\n",
        "        print(df)\r\n",
        "\r\n",
        "    if analysis:\r\n",
        "        exploratoryDataAnalysis(df)\r\n",
        "\r\n",
        "    # Selecting Features\r\n",
        "    Data = df[['ARRIVAL_DELAY','ORIGIN','DESTINATION','DISTANCE','TAXI_OUT','DEPARTURE_DELAY','DATE','DAY','AIRLINE','SCHEDULED_DEPARTURE','SCHEDULED_ARRIVAL']].copy()\r\n",
        "\r\n",
        "\r\n",
        "    # Handling Date and Time Data\r\n",
        "\r\n",
        "    SD = Data['SCHEDULED_DEPARTURE']\r\n",
        "    SA = Data['SCHEDULED_ARRIVAL']\r\n",
        "    DA = Data['DATE']\r\n",
        "\r\n",
        "    Data['SDH_Sin'] = [sin(2*pi*d.hour/24) for d in SD]\r\n",
        "    Data['SDH_Cos'] = [cos(2*pi*d.hour/24) for d in SD]\r\n",
        "    Data['SDM_Sin'] = [sin(2*pi*d.minute/60) for d in SD]\r\n",
        "    Data['SDM_Cos'] = [cos(2*pi*d.minute/60) for d in SD]\r\n",
        "\r\n",
        "    Data['SAH_Sin'] = [sin(2*pi*d.hour/24) for d in SA]\r\n",
        "    Data['SAH_Cos'] = [cos(2*pi*d.hour/24) for d in SA]\r\n",
        "    Data['SAM_Sin'] = [sin(2*pi*d.minute/60) for d in SA]\r\n",
        "    Data['SAM_Cos'] = [cos(2*pi*d.minute/60) for d in SA]\r\n",
        "\r\n",
        "    Data['DAM_Sin'] = [sin(2*pi*d.month/12) for d in DA]\r\n",
        "    Data['DAM_Cos'] = [cos(2*pi*d.month/12) for d in DA]\r\n",
        "    Data['DAD_Sin'] = [sin(2*pi*d.day/31) for d in DA]\r\n",
        "    Data['DAD_Cos'] = [cos(2*pi*d.day/31) for d in DA]\r\n",
        "\r\n",
        "    Data = Data.drop(['SCHEDULED_DEPARTURE','SCHEDULED_ARRIVAL','DATE'],axis=1)\r\n",
        "    Data.dropna(inplace=True)\r\n",
        "    Data.reset_index(inplace=True,drop=True)\r\n",
        "\r\n",
        "    if analysis:\r\n",
        "        print(Data)\r\n",
        "\r\n",
        "\r\n",
        "    # Handling Categorical Variables\r\n",
        "    \r\n",
        "    L = LabelEncoder()\r\n",
        "\r\n",
        "    Data['AIRLINE']=L.fit_transform(np.array(Data['AIRLINE']).reshape(-1,1))\r\n",
        "    Data['ORIGIN']=L.fit_transform(np.array(Data['ORIGIN']).reshape(-1,1))\r\n",
        "    Data['DESTINATION']=L.fit_transform(np.array(Data['DESTINATION']).reshape(-1,1))\r\n",
        "\r\n",
        "    H = OneHotEncoder()\r\n",
        "\r\n",
        "    a = pd.DataFrame(H.fit_transform(np.array(Data['AIRLINE']).reshape(-1,1)).toarray())\r\n",
        "    a.columns = [str(i) for i in range(len(a.columns))]\r\n",
        "    b = pd.DataFrame(H.fit_transform(np.array(Data['ORIGIN']).reshape(-1,1)).toarray())\r\n",
        "    b.columns = [str(i+len(a.columns)) for i in range(len(b.columns))]\r\n",
        "    c = pd.DataFrame(H.fit_transform(np.array(Data['DESTINATION']).reshape(-1,1)).toarray())\r\n",
        "    c.columns = [str(i+len(a.columns)+len(b.columns)) for i in range(len(c.columns))]\r\n",
        "\r\n",
        "    Data = Data.drop(['AIRLINE'],axis=1)\r\n",
        "    Data = Data.join(a)\r\n",
        "    #Data = Data.drop(['ORIGIN'],axis=1)\r\n",
        "    #Data = Data.join(b)\r\n",
        "    #Data = Data.drop(['DESTINATION'],axis=1)\r\n",
        "    #Data = Data.join(c)\r\n",
        "    Data.dropna(inplace=True)\r\n",
        "\r\n",
        "    if analysis:\r\n",
        "        print(Data)\r\n",
        "\r\n",
        "\r\n",
        "    # Splitting into X and Y\r\n",
        "\r\n",
        "    X = Data.copy()\r\n",
        "    X.drop(['ARRIVAL_DELAY'],axis=1, inplace = True)\r\n",
        "    Y = Data['ARRIVAL_DELAY'].copy()\r\n",
        "\r\n",
        "    for i in range(len(Y)):\r\n",
        "        if Y[i]<3: Y[i]=0\r\n",
        "        else: Y[i]=1\r\n",
        "\r\n",
        "    X = X.to_numpy()\r\n",
        "    Y = Y.to_numpy()\r\n",
        "    \r\n",
        "    if analysis:\r\n",
        "        print(\"X shape: \", X.shape)\r\n",
        "        print(\"Y shape: \", Y.shape)\r\n",
        "\r\n",
        "\r\n",
        "    # Splitting into Train, Val, Test\r\n",
        "\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.3, random_state=0, stratify = Y)\r\n",
        "    X_val, X_test, y_val, y_test = train_test_split( X_test, y_test, test_size=0.66, random_state=0, stratify = y_test)\r\n",
        "\r\n",
        "    if analysis:\r\n",
        "        print(f\"X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}\")\r\n",
        "        print(f\"y_train: {y_train.shape}, y_val: {y_val.shape}, y_test: {y_test.shape}\")\r\n",
        "\r\n",
        "\r\n",
        "    # Standard Scaling\r\n",
        "\r\n",
        "    scaler = StandardScaler()\r\n",
        "    scaler.fit(X_train)\r\n",
        "    X_train = scaler.transform(X_train)\r\n",
        "    X_val = scaler.transform(X_val)\r\n",
        "    X_test = scaler.transform(X_test)\r\n",
        "\r\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\r\n",
        "\r\n",
        "\r\n",
        "def train(model, X_train, y_train, X_val, y_val, X_test, y_test):\r\n",
        "\r\n",
        "    # Logistic Regression\r\n",
        "    if model == \"logistic\":\r\n",
        "\r\n",
        "        logistic = LogisticRegression()\r\n",
        "        logistic.fit(X_train,y_train)\r\n",
        "        y_pred = logistic.predict(X_test)\r\n",
        "\r\n",
        "        confusionMatrix = metrics.confusion_matrix(y_test, y_pred)\r\n",
        "        score = logistic.score(X_test,y_test)\r\n",
        "        print(\"Test Score:\", score)\r\n",
        "\r\n",
        "        sns.set(context=\"paper\")\r\n",
        "        plt.subplots(figsize=(6,6))\r\n",
        "        sns.heatmap(confusionMatrix, annot=True, fmt=\".0f\", linewidths=1.5, square = True);\r\n",
        "        plt.ylabel('Actual label');\r\n",
        "        plt.xlabel('Predicted label');\r\n",
        "        plt.title(\"Confusion Matrix\", size = 15);\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # SGD Classifier\r\n",
        "    if model == \"sgd classifier\":\r\n",
        "\r\n",
        "        sgd = SGDClassifier()\r\n",
        "        sgd.fit(X_train,y_train)\r\n",
        "        y_pred = sgd.predict(X_test)\r\n",
        "\r\n",
        "        confusionMatrix = metrics.confusion_matrix(y_test, y_pred)\r\n",
        "        score = sgd.score(X_test,y_test)\r\n",
        "        print(\"Test Score:\", score)\r\n",
        "\r\n",
        "        sns.set(context=\"paper\")\r\n",
        "        plt.subplots(figsize=(6,6))\r\n",
        "        sns.heatmap(confusionMatrix, annot=True, fmt=\".0f\", linewidths=1.5, square = True, cmap = 'winter');\r\n",
        "        plt.ylabel('Actual label');\r\n",
        "        plt.xlabel('Predicted label');\r\n",
        "        plt.title(\"Confusion Matrix\", size = 15);\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # Support Vector Machines\r\n",
        "    if model == \"svm\":\r\n",
        "\r\n",
        "        svc = BalancedBaggingClassifier(svm.LinearSVC(), n_jobs=-1)\r\n",
        "        svc.fit(X_train,y_train)\r\n",
        "        y_pred = svc.predict(X_test)\r\n",
        "\r\n",
        "        confusionMatrix = metrics.confusion_matrix(y_test, y_pred)\r\n",
        "        score = svc.score(X_test,y_test)\r\n",
        "        print(\"Test Score:\", score)\r\n",
        "\r\n",
        "        sns.set(context=\"paper\")\r\n",
        "        plt.subplots(figsize=(6,6))\r\n",
        "        sns.heatmap(confusionMatrix, annot=True, fmt=\".0f\", linewidths=1.5, square = True, cmap = 'winter');\r\n",
        "        plt.ylabel('Actual label');\r\n",
        "        plt.xlabel('Predicted label');\r\n",
        "        plt.title(\"Confusion Matrix\", size = 15);\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # Random Forests\r\n",
        "    if model == \"rf\":\r\n",
        "\r\n",
        "        rf = RandomForestClassifier()\r\n",
        "        rf.fit(X_train,y_train)\r\n",
        "        y_pred = rf.predict(X_test)\r\n",
        "\r\n",
        "        confusionMatrix = metrics.confusion_matrix(y_test, y_pred)\r\n",
        "        score = rf.score(X_test,y_test)\r\n",
        "        print(\"Test Score:\", score)\r\n",
        "\r\n",
        "        sns.set(context=\"paper\")\r\n",
        "        plt.subplots(figsize=(6,6))\r\n",
        "        sns.heatmap(confusionMatrix, annot=True, fmt=\".0f\", linewidths=1.5, square = True, cmap = 'winter');\r\n",
        "        plt.ylabel('Actual label');\r\n",
        "        plt.xlabel('Predicted label');\r\n",
        "        plt.title(\"Confusion Matrix\", size = 15);\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # Gaussian Naive Bayes\r\n",
        "    if model == \"gnb\":\r\n",
        "\r\n",
        "        gnb = GaussianNB()\r\n",
        "        gnb.fit(X_train,y_train)\r\n",
        "        y_pred = gnb.predict(X_test)\r\n",
        "\r\n",
        "        confusionMatrix = metrics.confusion_matrix(y_test, y_pred)\r\n",
        "        score = gnb.score(X_test,y_test)\r\n",
        "        print(\"Test Score:\", score)\r\n",
        "\r\n",
        "        sns.set(context=\"paper\")\r\n",
        "        plt.subplots(figsize=(6,6))\r\n",
        "        sns.heatmap(confusionMatrix, annot=True, fmt=\".0f\", linewidths=1.5, square = True, cmap = 'winter');\r\n",
        "        plt.ylabel('Actual label');\r\n",
        "        plt.xlabel('Predicted label');\r\n",
        "        plt.title(\"Confusion Matrix\", size = 15);\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # XGBoost Classifier\r\n",
        "    if model == \"xgb\":\r\n",
        "\r\n",
        "        xgb = XGBClassifier()\r\n",
        "        xgb.fit(X_train,y_train)\r\n",
        "        y_pred = xgb.predict(X_test)\r\n",
        "\r\n",
        "        confusionMatrix = metrics.confusion_matrix(y_test, y_pred)\r\n",
        "        score = xgb.score(X_test,y_test)\r\n",
        "        print(\"Test Score:\", score)\r\n",
        "\r\n",
        "        sns.set(context=\"paper\")\r\n",
        "        plt.subplots(figsize=(6,6))\r\n",
        "        sns.heatmap(confusionMatrix, annot=True, fmt=\".0f\", linewidths=1.5, square = True, cmap = 'winter');\r\n",
        "        plt.ylabel('Actual label');\r\n",
        "        plt.xlabel('Predicted label');\r\n",
        "        plt.title(\"Confusion Matrix\", size = 15);\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "    \r\n",
        "    # Neural Networks\r\n",
        "    if model == \"nn\":\r\n",
        "        pass\r\n",
        "\r\n",
        "\r\n",
        "def optimalParams(model, X_train, y_train, X_val, y_val, X_test, y_test):\r\n",
        "    '''\r\n",
        "    Enter the parameter and it's possible types here \r\n",
        "    If max_depth = 10,100,1000 and loss = L1,L2\r\n",
        "    The code will run 3*2 times.\r\n",
        "    For plotting the graph, please keep only 2 sets of parameters as it's a 2D graph.\r\n",
        "    Otherwise one would have to split the array and it will lead to confusion.\r\n",
        "    '''\r\n",
        "\r\n",
        "    # # Logistic Regression\r\n",
        "    if model == \"logistic\":\r\n",
        "\r\n",
        "        parameters = {\r\n",
        "            'penalty': ['l2'],\r\n",
        "            'fit_intercept': [True, False],\r\n",
        "            'max_iter': [2,4,6,8,10],\r\n",
        "            'n_jobs': [-1]}\r\n",
        "\r\n",
        "        clf = GridSearchCV(LogisticRegression(), parameters, n_jobs=-1, cv=3)\r\n",
        "        clf.fit(X_train,y_train)\r\n",
        "        print(\"Best Score:\", clf.best_score_)\r\n",
        "        print(\"Best Parameters:\", clf.best_params_)\r\n",
        "\r\n",
        "        bestEstimator = clf.best_estimator_\r\n",
        "        y_pred = bestEstimator.predict(X_test)\r\n",
        "        score = bestEstimator.score(X_test,y_test)\r\n",
        "        print(\"Test Score:\", score)\r\n",
        "\r\n",
        "\r\n",
        "        # Plotting the parameters\r\n",
        "\r\n",
        "        param_xAxis_name = 'max_iter' # parameter that you want in the x axis. (max_iter, n_estimators etc. are preferred)\r\n",
        "        param_color_name = 'fit_intercept' # parameter that you want as the different colored curves\r\n",
        "\r\n",
        "        param_xAxis = parameters[param_xAxis_name]\r\n",
        "        param_color = parameters[param_color_name]\r\n",
        "\r\n",
        "        mean_test_score = clf.cv_results_['mean_test_score']\r\n",
        "        mean_test_score = np.array(mean_test_score).reshape(len(param_color), len(param_xAxis))\r\n",
        "\r\n",
        "        _, ax = plt.subplots(1,1, figsize=(9,6))\r\n",
        "\r\n",
        "        for i in range(len(param_color)):\r\n",
        "            ax.plot(param_xAxis, mean_test_score[i,:], label=param_color_name+': ' + str(param_color[i]))\r\n",
        "\r\n",
        "        ax.set_title(\"Grid Search CV Scores for Logistic Regression\", fontsize=18, fontweight='bold')\r\n",
        "        ax.set_xlabel(param_xAxis_name, fontsize=14)\r\n",
        "        ax.set_ylabel('CV Avg Score', fontsize=14)\r\n",
        "        ax.legend(fontsize=14)\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # # SGDClassifier\r\n",
        "    if model == \"sgd classifier\":\r\n",
        "\r\n",
        "        parameters = {\r\n",
        "            'penalty': ['l1','l2'],\r\n",
        "            'max_iter': [50, 100, 250, 500, 1000, 2500, 5000, 7500, 10000],\r\n",
        "            'n_jobs': [-1]}\r\n",
        "\r\n",
        "        clf = GridSearchCV(SGDClassifier(), parameters, n_jobs=-1, cv=4)\r\n",
        "        clf.fit(X_train,y_train)\r\n",
        "        print(\"Best Score:\", clf.best_score_)\r\n",
        "        print(\"Best Parameters:\", clf.best_params_)\r\n",
        "\r\n",
        "        bestEstimator = clf.best_estimator_\r\n",
        "        y_pred = bestEstimator.predict(X_test)\r\n",
        "        score = bestEstimator.score(X_test,y_test)\r\n",
        "        print(\"Test Score:\", score)\r\n",
        "\r\n",
        "        # Plotting the parameters\r\n",
        "\r\n",
        "        param_xAxis_name = 'max_iter' # parameter that you want in the x axis. (max_iter, n_estimators etc. are preferred)\r\n",
        "        param_color_name = 'penalty' # parameter that you want as the different colored curves\r\n",
        "\r\n",
        "        param_xAxis = parameters[param_xAxis_name]\r\n",
        "        param_color = parameters[param_color_name]\r\n",
        "\r\n",
        "        mean_test_score = clf.cv_results_['mean_test_score']\r\n",
        "        mean_test_score = np.array(mean_test_score).reshape(len(param_color), len(param_xAxis))\r\n",
        "\r\n",
        "        _, ax = plt.subplots(1,1, figsize=(9,6))\r\n",
        "\r\n",
        "        for i in range(len(param_color)):\r\n",
        "            ax.plot(param_xAxis, mean_test_score[i,:], label=param_color_name+': ' + str(param_color[i]))\r\n",
        "\r\n",
        "        ax.set_title(\"Grid Search CV Scores for SGD Classifier\", fontsize=18, fontweight='bold')\r\n",
        "        ax.set_xlabel(param_xAxis_name, fontsize=14)\r\n",
        "        ax.set_ylabel('CV Avg Score', fontsize=14)\r\n",
        "        ax.legend(fontsize=14)\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # Support Vector Machines\r\n",
        "    if model == \"svm\":\r\n",
        "\r\n",
        "        parameters = {\r\n",
        "            'penalty': ['l1','l2'],\r\n",
        "            'max_iter': [50, 100, 250, 500, 1000, 2500, 5000, 7500, 10000]}\r\n",
        "\r\n",
        "        clf = GridSearchCV(svm.LinearSVC(), parameters, n_jobs=-1, cv=4)\r\n",
        "        clf.fit(X_train,y_train)\r\n",
        "        print(\"Best Score:\", clf.best_score_)\r\n",
        "        print(\"Best Parameters:\", clf.best_params_)\r\n",
        "\r\n",
        "        bestEstimator = clf.best_estimator_\r\n",
        "        y_pred = bestEstimator.predict(X_test)\r\n",
        "        score = bestEstimator.score(X_test,y_test)\r\n",
        "        print(\"Test Score:\", score)\r\n",
        "\r\n",
        "        # Plotting the parameters\r\n",
        "\r\n",
        "        param_xAxis_name = 'max_iter' # parameter that you want in the x axis. (max_iter, n_estimators etc. are preferred)\r\n",
        "        param_color_name = 'penalty' # parameter that you want as the different colored curves\r\n",
        "\r\n",
        "        param_xAxis = parameters[param_xAxis_name]\r\n",
        "        param_color = parameters[param_color_name]\r\n",
        "\r\n",
        "        mean_test_score = clf.cv_results_['mean_test_score']\r\n",
        "        mean_test_score = np.array(mean_test_score).reshape(len(param_color), len(param_xAxis))\r\n",
        "\r\n",
        "        _, ax = plt.subplots(1,1, figsize=(9,6))\r\n",
        "\r\n",
        "        for i in range(len(param_color)):\r\n",
        "            ax.plot(param_xAxis, mean_test_score[i,:], label=param_color_name+': ' + str(param_color[i]))\r\n",
        "\r\n",
        "        ax.set_title(\"Grid Search CV Scores for SVC\", fontsize=18, fontweight='bold')\r\n",
        "        ax.set_xlabel(param_xAxis_name, fontsize=14)\r\n",
        "        ax.set_ylabel('CV Avg Score', fontsize=14)\r\n",
        "        ax.legend(fontsize=14)\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # Random Forests\r\n",
        "    if model == \"rf\":\r\n",
        "        \r\n",
        "        parametersrf = {\r\n",
        "            'criterion': [\"gini\", \"entropy\"],\r\n",
        "            'class_weight': [None, \"balanced\"],\r\n",
        "            'n_estimators': [200,400,600]\r\n",
        "            }\r\n",
        "\r\n",
        "        clfrf = GridSearchCV(RandomForestClassifier(), parametersrf, n_jobs=-1, cv=3)\r\n",
        "        clfrf.fit(X_train,y_train)\r\n",
        "        print(\"Best Score:\", clfrf.best_score_)\r\n",
        "        print(\"Best Parameters:\", clfrf.best_params_)\r\n",
        "        bestEstimatorrf = clfrf.best_estimator_\r\n",
        "\r\n",
        "        y_pred = bestEstimatorrf.predict(X_test)\r\n",
        "\r\n",
        "        confusionMatrix = metrics.confusion_matrix(y_test, y_pred)\r\n",
        "        score = bestEstimatorrf.score(X_test,y_test)\r\n",
        "        print(\"Test Score:\", score)\r\n",
        "\r\n",
        "        param_xAxis_name = 'n_estimators' # parameter that you want in the x axis. (max_iter, n_estimators etc. are preferred)\r\n",
        "        param_color_name = 'criterion' # parameter that you want as the different colored curves\r\n",
        "\r\n",
        "        param_xAxis = parametersrf[param_xAxis_name]\r\n",
        "        param_color = parametersrf[param_color_name]\r\n",
        "        param_label = parameters[\"class_weight\"]\r\n",
        "        mean_test_score = clfrf.cv_results_['mean_test_score']\r\n",
        "        mean_test_score_none = mean_test_score[:len(mean_test_score)//2]\r\n",
        "        mean_test_score_bal = mean_test_score[len(mean_test_score)//2:]\r\n",
        "        mean_test_score_none = np.array(mean_test_score_none).reshape(len(param_color), len(param_xAxis))\r\n",
        "        mean_test_score_bal = np.array(mean_test_score_bal).reshape(len(param_color), len(param_xAxis))\r\n",
        "\r\n",
        "\r\n",
        "        _, ax = plt.subplots(1,1, figsize=(9,6))\r\n",
        "\r\n",
        "        for i in range(len(param_color)):\r\n",
        "            ax.plot(param_xAxis, mean_test_score_none[i,:], label=param_color_name+': ' + str(param_color[i]) + \", class weight:\" + str(param_label[i]))\r\n",
        "            ax.plot(param_xAxis, mean_test_score_bal[i,:], label=param_color_name+': ' + str(param_color[i]) + \", class weight:\" + str(param_label[i]))\r\n",
        "\r\n",
        "        ax.set_title(\"Grid Search CV Scores for Random Forest Classifier\", fontsize=18, fontweight='bold')\r\n",
        "        ax.set_xlabel(param_xAxis_name, fontsize=14)\r\n",
        "        ax.set_ylabel('CV Avg Score', fontsize=14)\r\n",
        "        ax.legend(fontsize=14, bbox_to_anchor=(1.05, 1), title = \"Criterion, class weight\")\r\n",
        "        plt.setp(legend.get_title(),fontsize='x-large')\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # Gaussian Naive Bayes\r\n",
        "    if model == \"gnb\":\r\n",
        "\r\n",
        "        parametersnb = {\r\n",
        "            \"var_smoothing\": [10**-20,10**-11,10**-9, 10**-7, 10**-5, 10**-2]\r\n",
        "            }\r\n",
        "\r\n",
        "        clfnb = GridSearchCV(GaussianNB(), parametersnb, n_jobs=-1, cv=3)\r\n",
        "        clfnb.fit(X_train,y_train)\r\n",
        "        print(\"Best Score:\", clfnb.best_score_)\r\n",
        "        print(\"Best Parameters:\", clfnb.best_params_)\r\n",
        "        bestEstimatornb = clfnb.best_estimator_\r\n",
        "        y_pred = bestEstimatornb.predict(X_test)\r\n",
        "\r\n",
        "        confusionMatrix = metrics.confusion_matrix(y_test, y_pred)\r\n",
        "        print(confusionMatrix)\r\n",
        "        scorenb = bestEstimatornb.score(X_test,y_test)\r\n",
        "        print(\"Test Score:\", scorenb)\r\n",
        "\r\n",
        "        param_xAxis_name = 'var_smoothing' # parameter that you want in the x axis. (max_iter, n_estimators etc. are preferred)\r\n",
        "        param_xAxis = parameters[param_xAxis_name]\r\n",
        "        param_label = parameters[param_xAxis_name]\r\n",
        "        print(clfnb.cv_results_[\"params\"])\r\n",
        "        mean_test_score = clfnb.cv_results_['mean_test_score']\r\n",
        "\r\n",
        "        _, ax = plt.subplots(1,1, figsize=(9,6))\r\n",
        "\r\n",
        "        ax.plot(param_xAxis, mean_test_score)\r\n",
        "        ax.set_title(\"Grid Search CV Scores for Gaussian naive bayes\", fontsize=18, fontweight='bold')\r\n",
        "        ax.set_xlabel(param_xAxis_name, fontsize=14)\r\n",
        "        ax.set_ylabel('CV Avg Score', fontsize=14)\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    # XGBoost Classifier\r\n",
        "    if model == \"xgb\":\r\n",
        "\r\n",
        "        parameters = {\r\n",
        "            'max_depth':[5,7,15],\r\n",
        "            'learning_rate': [0.01,0.001,0.1],\r\n",
        "            'class_weight': [None, \"balanced\"],\r\n",
        "            'n_estimators': [100,200,300]\r\n",
        "            }\r\n",
        "\r\n",
        "        clf = GridSearchCV(XGBClassifier(), parameters, n_jobs=-1, cv=3)\r\n",
        "        clf.fit(X_train,y_train)\r\n",
        "        print(\"Best Score:\", clf.best_score_)\r\n",
        "        print(\"Best Parameters:\", clf.best_params_)\r\n",
        "        bestEstimator = clf.best_estimator_\r\n",
        "        y_pred = bestEstimator.predict(X_test)\r\n",
        "\r\n",
        "        confusionMatrix = metrics.confusion_matrix(y_test, y_pred)\r\n",
        "        score = bestEstimator.score(X_test,y_test)\r\n",
        "        print(\"Test Score:\", score)\r\n",
        "\r\n",
        "        # Plotting the parameters\r\n",
        "\r\n",
        "        param_xAxis_name = 'n_estimators' # parameter that you want in the x axis. (max_iter, n_estimators etc. are preferred)\r\n",
        "        param_color_name = 'max_depth' # parameter that you want as the different colored curves\r\n",
        "\r\n",
        "        param_xAxis = parameters[param_xAxis_name]\r\n",
        "        param_color = parameters[param_color_name]\r\n",
        "        param_breaks = clf.cv_results_[\"params\"]\r\n",
        "        mean_score = clf.cv_results_[\"mean_test_score\"]\r\n",
        "        scores_list = [[] for i in range(6)]\r\n",
        "        j, k = len(param_xAxis)*len(param_color), 0\r\n",
        "        labels = dict()\r\n",
        "        for i in param_breaks:\r\n",
        "            scores_list[k//j].append(mean_score[k]) \r\n",
        "            labels[\"learning_rate:\"+str(clf.cv_results_[\"params\"][k][\"learning_rate\"]) + \", class_weight:\"+str(clf.cv_results_[\"params\"][k][\"class_weight\"])] = k//j\r\n",
        "            k += 1\r\n",
        "\r\n",
        "        labels = {v: k for k, v in labels.items()}\r\n",
        "        mean_test_score = np.array(scores_list).reshape(len(scores_list), len(param_color), len(param_xAxis))\r\n",
        "\r\n",
        "        _, ax = plt.subplots(1,1, figsize=(9,6))\r\n",
        "\r\n",
        "        for i in range(len(param_color)):\r\n",
        "            for j in range(len(mean_test_score)):\r\n",
        "                ax.plot(param_xAxis, mean_test_score[j,i,:], label=param_color_name+': ' + str(param_color[i]) + \",\" + labels[j])\r\n",
        "            \r\n",
        "\r\n",
        "        ax.set_title(\"Grid Search CV Scores for XGB Classifier\", fontsize=18, fontweight='bold')\r\n",
        "        ax.set_xlabel(param_xAxis_name, fontsize=14)\r\n",
        "        ax.set_ylabel('CV Avg Score', fontsize=14)\r\n",
        "        ax.legend(fontsize=14,  bbox_to_anchor=(1, 1.1), title = \"max depth, learning rate, class weight\")\r\n",
        "        plt.setp(legend.get_title(),fontsize='x-large')\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "\r\n",
        "def plotRocAuc(model, X_train, y_train, X_val, y_val, X_test, y_test):\r\n",
        "\r\n",
        "    if model == \"logistic\":\r\n",
        "        logistic = LogisticRegression()\r\n",
        "        logistic.fit(X_train,y_train)\r\n",
        "        y_pred_logistic = logistic.predict_proba(X_test)\r\n",
        "\r\n",
        "        fpr_logistic, tpr_logistic, threshold_logistic = metrics.roc_curve(y_test, y_pred_logistic[:, 1])\r\n",
        "        roc_auc = metrics.auc(fpr_logistic, tpr_logistic)\r\n",
        "\r\n",
        "        plt.subplots(figsize=(9,7))\r\n",
        "        plt.title(\"Receiver Operating Characteristic\", fontsize=14)\r\n",
        "        plt.plot(fpr, tpr, label = \"Logistic Regression AUC = %0.2f\"%roc_auc)\r\n",
        "        plt.plot([0,1], [0,1], \"--\", label=\"No skill\")\r\n",
        "        plt.legend(loc = \"lower right\", prop={'size': 12})\r\n",
        "        plt.ylabel(\"True Positive Rate\")\r\n",
        "        plt.xlabel(\"False Positive Rate\")\r\n",
        "\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "\r\n",
        "def runner(model, analysis = False, optimal = False):\r\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test = preprocess(analysis)\r\n",
        "    train(model, X_train, y_train, X_val, y_val, X_test, y_test)\r\n",
        "    if optimal:\r\n",
        "        optimalParams(model, X_train, y_train, X_val, y_val, X_test, y_test)\r\n",
        "    plotRocAuc(model, X_train, y_train, X_val, y_val, X_test, y_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "wEONz5_UqF39",
        "outputId": "ef78557c-9ebd-4852-b060-7a1dceb5a70b"
      },
      "source": [
        "runner(model = \"rf\", analysis = False, optimal = False)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Score: 0.8739967719825775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_hMNV6OqIxt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}